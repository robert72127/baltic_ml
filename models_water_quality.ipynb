{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ac043c",
   "metadata": {},
   "source": [
    "### Created simple parameter : 0.4*OXY + 0.3*SECCHI + 0.3*CHLORA measuring water quality and tried predicting it on models provided at models.ipynb with some small modifications, using elements from fertilizers and silicate as X\n",
    "### works ok mostly based on silicates,  but other matters too r2_score better at greater depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from functools import reduce\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aefea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default paths to files generated with data_splitting\n",
    "DATA_BASE = '2022.11.07-merged-single-observation/'\n",
    "PATHS = ['100', '1000', '1500','2000', '2500', 'average', 'deep', 'standard']\n",
    "DATA_FILE = '/CLEANED_MERGED_DATA.csv'\n",
    "DATA_PATH = DATA_BASE + PATHS[6] + DATA_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATAPATH is path to your file\n",
    "df = pd.read_csv(DATA_PATH,index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b557251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop date and normalize rest of columns\n",
    "df = df.drop(['DATE'], axis=1)\n",
    "cols = list(set(df.columns))\n",
    "df[cols] -= df[cols].min()\n",
    "df[cols] /= df[cols].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c85cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality is linear combitnation of few other parameters\n",
    "# we used elements occuring in fertilizers and SIO2 (silicate) which comes from rivers as X\n",
    "\n",
    "X_cols = ['TP', 'TN', 'NO3','NO2','PO4', 'NH4', 'SIO2']\n",
    "df['quality'] = 0.4*df['OXY'] + 0.3*df['SECCHI'] + 0.3*df['CHLORA']\n",
    "y_col = ['quality']\n",
    "\n",
    "X = df[X_cols]\n",
    "y = df[y_col]\n",
    "y = column_or_1d(y, warn=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true  ) ) ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "lg = LinearRegression()\n",
    "lg.fit(x_train, y_train)\n",
    "y_pred = lg.predict(x_test)\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting regression\n",
    "bg = GradientBoostingRegressor()\n",
    "bg.fit(x_train, y_train)\n",
    "y_pred = bg.predict(x_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4952631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural netword\n",
    "mlp = MLPRegressor(activation='logistic', hidden_layer_sizes=(2,2), solver='sgd', max_iter=3000)\n",
    "mlp.fit(x_train,y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest \n",
    "rfr = RandomForestRegressor(random_state=0)\n",
    "rfr.fit(x_train, y_train)\n",
    "y_pred = rfr.predict(x_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84579946",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_lebels = x_train.columns[0:]\n",
    "importances  = rfr.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "index_list = []\n",
    "value_list = []\n",
    "for i,j in zip(range(x_train.shape[1]-1),indices):\n",
    "    index_list.append(feat_lebels[j])\n",
    "    value_list.append(importances[j])\n",
    "    print(i+1, feat_lebels[j], importances[j])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(index_list[::-1],value_list[::-1])\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title('feature',fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':[50,75,100],\n",
    "    'min_samples_split':[2,3,5],\n",
    "    'min_samples_leaf':[1,2,3]\n",
    "}\n",
    "grid_seach_rf= GridSearchCV(estimator=RandomForestRegressor(random_state=0),param_grid=param_grid, scoring='neg_mean_squared_error', cv = 5)\n",
    "grid_seach_rf.fit(x_train, y_train)\n",
    "best = grid_seach_rf.best_params_\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff629f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27604b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "rfr_ = RandomForestRegressor(n_estimators=best['n_estimators'], min_samples_leaf=best['min_samples_leaf'], min_samples_split=best['min_samples_split'], random_state=0)\n",
    "rfr_.fit(x_train, y_train)\n",
    "y_pred = rfr_.predict(x_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14130008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# score\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=5)\n",
    "regressor.fit(x_train, y_train) \n",
    "y_pred = regressor.predict(x_test)\n",
    "print('sklearn score:{}'.format(r2_score(y_test, y_pred)))  \n",
    "\n",
    "errors = abs(y_pred - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:\\n', np.round(np.mean(errors), 2), 'degrees.')\n",
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:\\n', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = y_pred.shape[0]\n",
    "y_pred = pd.DataFrame(y_pred[-col:], index=range(col), columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ddf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(y_test[150:200], color='red', label='quality_test')\n",
    "plt.plot(y_pred[150:200], color='blue', label='quality_pred')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"quality\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dafb13e4b6f58b857a75d76bdb469c05d137ecb565f1b307667c72b2cf0b5b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
