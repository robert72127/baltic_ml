{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73e641a",
   "metadata": {},
   "source": [
    "## Purpouse of this notebook is to create new datasets from the one we have,\n",
    "### Firstly create separate folders for various depths,  one for averaged, and one for our base dataset\n",
    "### Then perform cleaning based on data_cleaning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e77ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "090fadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '2022.11.07-merged-single-observation'\n",
    "FILENAMES = [f for f in listdir(DATA_PATH) if (isfile(join(DATA_PATH, f)) and not f.startswith('.') and f.endswith('.csv'))]\n",
    "DEPTHS = [ 100, 500, 1000, 1500, 2000, 2500]\n",
    "MERGED_NAME = 'CLEANED_MERGED_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6c365fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function we will split by \n",
    "\n",
    "## helpful filters and statistical functions\n",
    "\n",
    "def fix_date_formatting(df):\n",
    "    df['DATE'] = pd.to_datetime(df.DATE, infer_datetime_format=True)\n",
    "    return df\n",
    "\n",
    "def filter_by_months(df, months):\n",
    "    return df[df['DATE'].dt.month == any(months)]\n",
    "\n",
    "def group_by_year(df, par):\n",
    "    df =  df.groupby(df['DATE'].dt.year)[par].mean()\n",
    "    return pd.DataFrame({\"DATE\":df.index, par:df.values})\n",
    "\n",
    "def group_by_date(df, par):\n",
    "    df =  df.groupby(df['DATE'].dt.date)[par].mean()\n",
    "    return pd.DataFrame({\"DATE\":df.index, par:df.values})\n",
    "\n",
    "def group_by_month(df, par):\n",
    "    #df = df.drop('DEPTH', axis=1)\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df = df.groupby(pd.Grouper(freq='M', key='DATE')).mean()\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def filter_by_depth(df, depth):\n",
    "    df = df.loc[df['DEPTH'] == depth]\n",
    "    return df\n",
    "\n",
    "def filter_by_depth_range(df, low, high):\n",
    "    df = df.loc[low <= df['DEPTH'] <= high]\n",
    "    return df\n",
    "\n",
    "def group_by_depth(df, par):\n",
    "    df =  df.groupby(df['DEPTH'])[par].mean()\n",
    "    return pd.DataFrame({\"DEPTH\":df.index, par:df.values})\n",
    "\n",
    "def drop_outliers(df,param, quantile):\n",
    "    q = df[param].quantile(quantile)\n",
    "    return df[df[param] < q]\n",
    "\n",
    "#return new dataframe with par replaced by it's movign average\n",
    "def moving_averages(df, param, window_size):\n",
    "    _df = df.copy()\n",
    "    _df[param] = df[param].rolling(window=window_size).mean()\n",
    "    return _df\n",
    "\n",
    "def apply_features_transform(df, param, quantile=.95, depth=[100, 2500], moving_avg_window=6):\n",
    "    df = fix_date_formatting(df)\n",
    "    #df = filter_by_depth_range(df, depth[0], depth[1])\n",
    "    df = df.drop('DEPTH', axis=1)\n",
    "    df = drop_outliers(df, param, quantile)\n",
    "    df = group_by_month(df, param)\n",
    "    df = moving_averages(df, param, moving_avg_window)\n",
    "    #df = group_by_year(df, param)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b822e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NO2.csv',\n",
       " 'NH4.csv',\n",
       " 'PH.csv',\n",
       " 'SECCHI.csv',\n",
       " 'CTDTMP.csv',\n",
       " 'CHLORA.csv',\n",
       " 'CTDSAL.csv',\n",
       " 'PO4.csv',\n",
       " 'OXY.csv',\n",
       " 'TP.csv',\n",
       " 'TN.csv',\n",
       " 'SIO2.csv',\n",
       " 'NO3.csv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "584643c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders for data if they don't exist inside DATA_PATH\n",
    "for d in ([str(d) for d in DEPTHS] + ['average', 'standard', 'deep']):\n",
    "    if not exists(DATA_PATH +'/'+ d):\n",
    "        makedirs(DATA_PATH + '/' + d)\n",
    "\n",
    "for file in FILENAMES:\n",
    "    ##read as csv\n",
    "    dataframe = pd.read_csv(DATA_PATH + '/' + file,index_col=False, )\n",
    "    ## get parameter from column name\n",
    "    param = dataframe.columns[2]\n",
    "    ## standard\n",
    "    dataframe.to_csv(DATA_PATH + '/standard/' + file,index=False)\n",
    "    dataframe['DATE'] = pd.to_datetime(dataframe['DATE'],dayfirst = True)\n",
    "    for d in DEPTHS:\n",
    "        depth_filtered = dataframe.loc[dataframe['DEPTH'] == d]\n",
    "        #depth_filtered = group_by_month(depth_filtered, param)\n",
    "        ## save to folder for this depth\n",
    "        depth_filtered.to_csv(DATA_PATH+'/'+str(d)+'/'+file,index=False)\n",
    "    ## do the same for averaged by depth\n",
    "    average = apply_features_transform(dataframe, param)\n",
    "    average.to_csv(DATA_PATH + '/average/' + file,index=False)\n",
    "    ## and for deep only\n",
    "    deep = dataframe.loc[2000 <= dataframe['DEPTH']]\n",
    "    deep.to_csv(DATA_PATH+'/deep/'+file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56435bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataframe merging csv files in directory\n",
    "def merge(path):\n",
    "    dfs = {filename: pd.read_csv(path + '/' + filename,index_col=False )\n",
    "           for filename in FILENAMES\n",
    "           if filename.endswith('.csv') and not filename.startswith('.')}\n",
    "\n",
    "    df_list=[]\n",
    "    for df in dfs.values():\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'],dayfirst = True)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    on = ['DATE', 'DEPTH']\n",
    "    if 'DEPTH' not in df_list[0].columns:\n",
    "        on = ['DATE'] \n",
    "    df = reduce(lambda left,right: pd.merge(left.drop_duplicates(subset=on)              ,right.drop_duplicates(subset=on)              ,on=on              ,how='outer'), df_list)\n",
    "    #df = reduce(lambda left,right: pd.merge(left.drop_duplicates(subset=['DATE','DEPTH']),right.drop_duplicates(subset=['DATE','DEPTH']),on=['DATE','DEPTH'],how='outer'), df_list)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d4d5f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NH4</th>\n",
       "      <th>PH</th>\n",
       "      <th>SECCHI</th>\n",
       "      <th>CTDTMP</th>\n",
       "      <th>CHLORA</th>\n",
       "      <th>CTDSAL</th>\n",
       "      <th>PO4</th>\n",
       "      <th>OXY</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>SIO2</th>\n",
       "      <th>NO3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-01-07</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.89</td>\n",
       "      <td>1.37</td>\n",
       "      <td>356.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.1</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-01-07</td>\n",
       "      <td>100</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.88</td>\n",
       "      <td>1.33</td>\n",
       "      <td>355.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.9</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-01-07</td>\n",
       "      <td>2500</td>\n",
       "      <td>1.14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.04</td>\n",
       "      <td>1.43</td>\n",
       "      <td>346.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-01-07</td>\n",
       "      <td>500</td>\n",
       "      <td>1.02</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.89</td>\n",
       "      <td>1.32</td>\n",
       "      <td>356.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.7</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-01-07</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.95</td>\n",
       "      <td>1.36</td>\n",
       "      <td>338.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>1975-12-02</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.70</td>\n",
       "      <td>8.5</td>\n",
       "      <td>19.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296.9</td>\n",
       "      <td>1.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>1975-12-02</td>\n",
       "      <td>2600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>1975-12-02</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.70</td>\n",
       "      <td>7.9</td>\n",
       "      <td>19.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>318.8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>1975-12-02</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.70</td>\n",
       "      <td>8.6</td>\n",
       "      <td>19.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.3</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>1975-12-02</td>\n",
       "      <td>2400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.20</td>\n",
       "      <td>13.4</td>\n",
       "      <td>19.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.3</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4768 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE  DEPTH   NO2  NH4  PH  SECCHI  CTDTMP  CHLORA  CTDSAL   PO4  \\\n",
       "0    1986-01-07   1000  1.05  5.6 NaN     NaN    2.47     NaN   17.89  1.37   \n",
       "1    1986-01-07    100  0.96  5.5 NaN     NaN    2.56     NaN   17.88  1.33   \n",
       "2    1986-01-07   2500  1.14  6.0 NaN     NaN    2.89     NaN   18.04  1.43   \n",
       "3    1986-01-07    500  1.02  5.5 NaN     NaN    2.56     NaN   17.89  1.32   \n",
       "4    1986-01-07   2000  1.03  5.8 NaN     NaN    2.63     NaN   17.95  1.36   \n",
       "...         ...    ...   ...  ...  ..     ...     ...     ...     ...   ...   \n",
       "4763 1975-12-02   1000   NaN  NaN NaN     NaN    6.70     8.5   19.20   NaN   \n",
       "4764 1975-12-02   2600   NaN  NaN NaN     NaN    8.50    20.0   20.10   NaN   \n",
       "4765 1975-12-02    100   NaN  NaN NaN     NaN    6.70     7.9   19.20   NaN   \n",
       "4766 1975-12-02   2000   NaN  NaN NaN     NaN    6.70     8.6   19.20   NaN   \n",
       "4767 1975-12-02   2400   NaN  NaN NaN     NaN    8.20    13.4   19.90   NaN   \n",
       "\n",
       "        OXY    TP  TN  SIO2   NO3  \n",
       "0     356.8   NaN NaN  23.1   8.4  \n",
       "1     355.9   NaN NaN  23.9   7.0  \n",
       "2     346.6   NaN NaN  25.1   9.7  \n",
       "3     356.8   NaN NaN  23.7   8.6  \n",
       "4     338.1   NaN NaN  24.5  10.0  \n",
       "...     ...   ...  ..   ...   ...  \n",
       "4763  296.9  1.58 NaN   NaN   NaN  \n",
       "4764  178.1  3.62 NaN   NaN   NaN  \n",
       "4765  318.8  1.71 NaN   NaN   NaN  \n",
       "4766  306.3  1.52 NaN   NaN   NaN  \n",
       "4767  206.3  2.68 NaN   NaN   NaN  \n",
       "\n",
       "[4768 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge(DATA_PATH + '/standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8209f4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 739 entries, 0 to 738\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     440 non-null    float64\n",
      " 1   NH4     453 non-null    float64\n",
      " 2   PH      125 non-null    float64\n",
      " 3   SECCHI  454 non-null    float64\n",
      " 4   CTDTMP  719 non-null    float64\n",
      " 5   CHLORA  485 non-null    float64\n",
      " 6   CTDSAL  715 non-null    float64\n",
      " 7   PO4     588 non-null    float64\n",
      " 8   OXY     714 non-null    float64\n",
      " 9   TP      642 non-null    float64\n",
      " 10  TN      425 non-null    float64\n",
      " 11  SIO2    465 non-null    float64\n",
      " 12  NO3     471 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 80.8 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 732 entries, 0 to 731\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     438 non-null    float64\n",
      " 1   NH4     447 non-null    float64\n",
      " 2   PH      126 non-null    float64\n",
      " 3   SECCHI  451 non-null    float64\n",
      " 4   CTDTMP  713 non-null    float64\n",
      " 5   CHLORA  421 non-null    float64\n",
      " 6   CTDSAL  715 non-null    float64\n",
      " 7   PO4     579 non-null    float64\n",
      " 8   OXY     712 non-null    float64\n",
      " 9   TP      640 non-null    float64\n",
      " 10  TN      419 non-null    float64\n",
      " 11  SIO2    461 non-null    float64\n",
      " 12  NO3     465 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 80.1 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 733 entries, 0 to 732\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     440 non-null    float64\n",
      " 1   NH4     449 non-null    float64\n",
      " 2   PH      126 non-null    float64\n",
      " 3   SECCHI  451 non-null    float64\n",
      " 4   CTDTMP  717 non-null    float64\n",
      " 5   CHLORA  485 non-null    float64\n",
      " 6   CTDSAL  713 non-null    float64\n",
      " 7   PO4     583 non-null    float64\n",
      " 8   OXY     711 non-null    float64\n",
      " 9   TP      639 non-null    float64\n",
      " 10  TN      421 non-null    float64\n",
      " 11  SIO2    463 non-null    float64\n",
      " 12  NO3     467 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 80.2 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 732 entries, 0 to 731\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     439 non-null    float64\n",
      " 1   NH4     448 non-null    float64\n",
      " 2   PH      126 non-null    float64\n",
      " 3   SECCHI  451 non-null    float64\n",
      " 4   CTDTMP  714 non-null    float64\n",
      " 5   CHLORA  453 non-null    float64\n",
      " 6   CTDSAL  713 non-null    float64\n",
      " 7   PO4     583 non-null    float64\n",
      " 8   OXY     711 non-null    float64\n",
      " 9   TP      637 non-null    float64\n",
      " 10  TN      418 non-null    float64\n",
      " 11  SIO2    462 non-null    float64\n",
      " 12  NO3     466 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 80.1 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 734 entries, 0 to 733\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     437 non-null    float64\n",
      " 1   NH4     445 non-null    float64\n",
      " 2   PH      126 non-null    float64\n",
      " 3   SECCHI  452 non-null    float64\n",
      " 4   CTDTMP  716 non-null    float64\n",
      " 5   CHLORA  484 non-null    float64\n",
      " 6   CTDSAL  714 non-null    float64\n",
      " 7   PO4     580 non-null    float64\n",
      " 8   OXY     710 non-null    float64\n",
      " 9   TP      635 non-null    float64\n",
      " 10  TN      417 non-null    float64\n",
      " 11  SIO2    460 non-null    float64\n",
      " 12  NO3     464 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 80.3 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 454 entries, 0 to 453\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     404 non-null    float64\n",
      " 1   NH4     400 non-null    float64\n",
      " 2   PH      126 non-null    float64\n",
      " 3   SECCHI  414 non-null    float64\n",
      " 4   CTDTMP  441 non-null    float64\n",
      " 5   CHLORA  217 non-null    float64\n",
      " 6   CTDSAL  440 non-null    float64\n",
      " 7   PO4     415 non-null    float64\n",
      " 8   OXY     437 non-null    float64\n",
      " 9   TP      377 non-null    float64\n",
      " 10  TN      375 non-null    float64\n",
      " 11  SIO2    414 non-null    float64\n",
      " 12  NO3     416 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 49.7 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 782 entries, 0 to 781\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     236 non-null    float64\n",
      " 1   NH4     259 non-null    float64\n",
      " 2   PH      47 non-null     float64\n",
      " 3   SECCHI  203 non-null    float64\n",
      " 4   CTDTMP  405 non-null    float64\n",
      " 5   CHLORA  321 non-null    float64\n",
      " 6   CTDSAL  411 non-null    float64\n",
      " 7   PO4     324 non-null    float64\n",
      " 8   OXY     404 non-null    float64\n",
      " 9   TP      365 non-null    float64\n",
      " 10  TN      238 non-null    float64\n",
      " 11  SIO2    270 non-null    float64\n",
      " 12  NO3     245 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 85.5 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4768 entries, 0 to 4767\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     2706 non-null   float64\n",
      " 1   NH4     2770 non-null   float64\n",
      " 2   PH      757 non-null    float64\n",
      " 3   SECCHI  2972 non-null   float64\n",
      " 4   CTDTMP  4574 non-null   float64\n",
      " 5   CHLORA  2995 non-null   float64\n",
      " 6   CTDSAL  4510 non-null   float64\n",
      " 7   PO4     3566 non-null   float64\n",
      " 8   OXY     4406 non-null   float64\n",
      " 9   TP      3967 non-null   float64\n",
      " 10  TN      2601 non-null   float64\n",
      " 11  SIO2    2848 non-null   float64\n",
      " 12  NO3     2882 non-null   float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 521.5 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1549 entries, 0 to 1548\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   NO2     933 non-null    float64\n",
      " 1   NH4     957 non-null    float64\n",
      " 2   PH      253 non-null    float64\n",
      " 3   SECCHI  960 non-null    float64\n",
      " 4   CTDTMP  1511 non-null   float64\n",
      " 5   CHLORA  905 non-null    float64\n",
      " 6   CTDSAL  1507 non-null   float64\n",
      " 7   PO4     1217 non-null   float64\n",
      " 8   OXY     1495 non-null   float64\n",
      " 9   TP      1347 non-null   float64\n",
      " 10  TN      902 non-null    float64\n",
      " 11  SIO2    981 non-null    float64\n",
      " 12  NO3     997 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 169.4 KB\n"
     ]
    }
   ],
   "source": [
    "## perform cleaning (see data_cleaning.ipynb)\n",
    "for path in ([str(i) for i in DEPTHS] + ['average', 'standard','deep']):\n",
    "    \n",
    "    df = merge(DATA_PATH + '/' + path)\n",
    "    \n",
    "    # rest of loop is mostly copy of regression method from data_cleaning.ipynb\n",
    "    # check missing values\n",
    "    df_missing = df.drop(['DATE'],axis=1)\n",
    "    missing = df_missing.isna().sum()\n",
    "    missing = pd.DataFrame(data={'elements': missing.index,'missing':missing.values})\n",
    "    missing = missing[~missing['missing'].isin([0])]\n",
    "    missing['percentage'] =  missing['missing']/df_missing.shape[0]\n",
    "    missing.sort_values(by='percentage',ascending=False)\n",
    "\n",
    "    # check df data type\n",
    "    #df_missing[missing['elements']].info()\n",
    "    \n",
    "    # check df data type\n",
    "    df_missing[missing['elements']].info()\n",
    "    if path != 'average':\n",
    "        df_missing = df_missing.drop(['DEPTH'],axis=1)\n",
    "    df_missing = df_missing.drop(['PH'],axis=1) # PH has too many missing values\n",
    "    # df_missing.head\n",
    "    \n",
    "    X_missing = df_missing.copy()\n",
    "    y_missing = df_missing.copy()\n",
    "    y_missing.dropna(inplace=True) \n",
    "    X_missing = pd.DataFrame(X_missing)\n",
    "    y_missing = pd.DataFrame(y_missing)\n",
    "\n",
    "    # regression method\n",
    "    X_missing_reg = X_missing.copy()\n",
    "    sortindex = np.argsort(X_missing_reg.isnull().sum(axis=0)).values #sort missing columns\n",
    "\n",
    "    for i in sortindex:\n",
    "        df_ = X_missing_reg  \n",
    "        fillc = df_.iloc[:, i]  \n",
    "        df_ = pd.concat([df_.drop(df_.columns[i], axis=1), pd.DataFrame(y_missing)], axis=1)\n",
    "        df_0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0).fit_transform(df_)\n",
    "        #train and test dataset\n",
    "        Ytrain = fillc[fillc.notnull()]  # not missing part is Y_train\n",
    "        Ytest = fillc[fillc.isnull()] \n",
    "        Xtrain = df_0[Ytrain.index, :]\n",
    "        Xtest = df_0[Ytest.index, :] \n",
    "        rfc = RandomForestRegressor(n_estimators=100) \n",
    "        rfc = rfc.fit(Xtrain, Ytrain)  \n",
    "        Ypredict = rfc.predict(Xtest)\n",
    "        # put prediction values back to df\n",
    "        X_missing_reg.loc[X_missing_reg.iloc[:, i].isnull(), X_missing_reg.columns[i]] = Ypredict\n",
    "\n",
    "\n",
    "    X_missing_reg.insert(0,column = 'DATE',value=df['DATE'])\n",
    "\n",
    "    ##save csv\n",
    "    X_missing_reg.to_csv(DATA_PATH  + '/' + path + '/' + MERGED_NAME + '.csv' ,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
